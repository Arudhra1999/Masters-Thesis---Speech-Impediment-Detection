{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "affde972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70b833fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device : cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device : {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87076844",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94b8ca4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): DistilBertModel(\n",
       "      (embeddings): Embeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (transformer): Transformer(\n",
       "        (layer): ModuleList(\n",
       "          (0-5): 6 x TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): lora.Linear(\n",
       "                (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): lora.Linear(\n",
       "                (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (activation): GELUActivation()\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"attention.q_lin\", \"attention.v_lin\"],\n",
    "    lora_dropout=0.1\n",
    ")\n",
    "lora_model = get_peft_model(model, lora_config)\n",
    "lora_model.to(device)\n",
    "lora_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2198eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Dataset/Final Dysarthria-Non Dysarthria Speech Features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28780ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4282, 10002)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75f5dc45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_9992</th>\n",
       "      <th>feature_9993</th>\n",
       "      <th>feature_9994</th>\n",
       "      <th>feature_9995</th>\n",
       "      <th>feature_9996</th>\n",
       "      <th>feature_9997</th>\n",
       "      <th>feature_9998</th>\n",
       "      <th>feature_9999</th>\n",
       "      <th>label</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-548.22070</td>\n",
       "      <td>-512.68445</td>\n",
       "      <td>-385.66476</td>\n",
       "      <td>-296.33347</td>\n",
       "      <td>-278.77200</td>\n",
       "      <td>-309.11040</td>\n",
       "      <td>-338.63345</td>\n",
       "      <td>-346.67023</td>\n",
       "      <td>-349.56323</td>\n",
       "      <td>-361.98727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-576.23540</td>\n",
       "      <td>-570.52356</td>\n",
       "      <td>-563.91724</td>\n",
       "      <td>-467.63490</td>\n",
       "      <td>-427.55084</td>\n",
       "      <td>-401.95612</td>\n",
       "      <td>-375.35630</td>\n",
       "      <td>-434.04730</td>\n",
       "      <td>-455.38083</td>\n",
       "      <td>-450.59012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-603.48150</td>\n",
       "      <td>-582.47845</td>\n",
       "      <td>-478.41200</td>\n",
       "      <td>-364.91333</td>\n",
       "      <td>-342.75296</td>\n",
       "      <td>-371.54932</td>\n",
       "      <td>-386.14365</td>\n",
       "      <td>-423.13620</td>\n",
       "      <td>-452.56390</td>\n",
       "      <td>-483.60983</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-616.47060</td>\n",
       "      <td>-587.69450</td>\n",
       "      <td>-589.40326</td>\n",
       "      <td>-587.86400</td>\n",
       "      <td>-579.49640</td>\n",
       "      <td>-549.48470</td>\n",
       "      <td>-470.16528</td>\n",
       "      <td>-390.60820</td>\n",
       "      <td>-333.97488</td>\n",
       "      <td>-301.32706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-577.04650</td>\n",
       "      <td>-575.76090</td>\n",
       "      <td>-583.78546</td>\n",
       "      <td>-572.81540</td>\n",
       "      <td>-571.20715</td>\n",
       "      <td>-574.68500</td>\n",
       "      <td>-572.63000</td>\n",
       "      <td>-568.56250</td>\n",
       "      <td>-563.06085</td>\n",
       "      <td>-558.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4277</th>\n",
       "      <td>-362.60742</td>\n",
       "      <td>-329.08860</td>\n",
       "      <td>-324.55450</td>\n",
       "      <td>-321.42572</td>\n",
       "      <td>-320.04068</td>\n",
       "      <td>-323.81036</td>\n",
       "      <td>-326.55673</td>\n",
       "      <td>-323.49510</td>\n",
       "      <td>-322.62424</td>\n",
       "      <td>-321.32010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4278</th>\n",
       "      <td>-351.61120</td>\n",
       "      <td>-325.73544</td>\n",
       "      <td>-320.22736</td>\n",
       "      <td>-318.81357</td>\n",
       "      <td>-321.31387</td>\n",
       "      <td>-319.99472</td>\n",
       "      <td>-317.29916</td>\n",
       "      <td>-316.92715</td>\n",
       "      <td>-320.76240</td>\n",
       "      <td>-322.99478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>-362.91858</td>\n",
       "      <td>-328.30580</td>\n",
       "      <td>-324.49197</td>\n",
       "      <td>-323.67795</td>\n",
       "      <td>-327.72690</td>\n",
       "      <td>-324.56934</td>\n",
       "      <td>-321.89062</td>\n",
       "      <td>-323.60220</td>\n",
       "      <td>-324.45087</td>\n",
       "      <td>-324.01114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4280</th>\n",
       "      <td>-346.29034</td>\n",
       "      <td>-320.42477</td>\n",
       "      <td>-319.24180</td>\n",
       "      <td>-317.26074</td>\n",
       "      <td>-320.89760</td>\n",
       "      <td>-320.12726</td>\n",
       "      <td>-317.15750</td>\n",
       "      <td>-310.82544</td>\n",
       "      <td>-315.87380</td>\n",
       "      <td>-322.21048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>-351.47990</td>\n",
       "      <td>-324.52698</td>\n",
       "      <td>-322.83804</td>\n",
       "      <td>-318.60500</td>\n",
       "      <td>-317.09293</td>\n",
       "      <td>-318.37054</td>\n",
       "      <td>-321.32846</td>\n",
       "      <td>-322.47766</td>\n",
       "      <td>-322.60980</td>\n",
       "      <td>-321.89868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4282 rows × 10002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
       "0    -548.22070 -512.68445 -385.66476 -296.33347 -278.77200 -309.11040   \n",
       "1    -576.23540 -570.52356 -563.91724 -467.63490 -427.55084 -401.95612   \n",
       "2    -603.48150 -582.47845 -478.41200 -364.91333 -342.75296 -371.54932   \n",
       "3    -616.47060 -587.69450 -589.40326 -587.86400 -579.49640 -549.48470   \n",
       "4    -577.04650 -575.76090 -583.78546 -572.81540 -571.20715 -574.68500   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "4277 -362.60742 -329.08860 -324.55450 -321.42572 -320.04068 -323.81036   \n",
       "4278 -351.61120 -325.73544 -320.22736 -318.81357 -321.31387 -319.99472   \n",
       "4279 -362.91858 -328.30580 -324.49197 -323.67795 -327.72690 -324.56934   \n",
       "4280 -346.29034 -320.42477 -319.24180 -317.26074 -320.89760 -320.12726   \n",
       "4281 -351.47990 -324.52698 -322.83804 -318.60500 -317.09293 -318.37054   \n",
       "\n",
       "      feature_6  feature_7  feature_8  feature_9  ...  feature_9992  \\\n",
       "0    -338.63345 -346.67023 -349.56323 -361.98727  ...           0.0   \n",
       "1    -375.35630 -434.04730 -455.38083 -450.59012  ...           0.0   \n",
       "2    -386.14365 -423.13620 -452.56390 -483.60983  ...           0.0   \n",
       "3    -470.16528 -390.60820 -333.97488 -301.32706  ...           0.0   \n",
       "4    -572.63000 -568.56250 -563.06085 -558.03760  ...           0.0   \n",
       "...         ...        ...        ...        ...  ...           ...   \n",
       "4277 -326.55673 -323.49510 -322.62424 -321.32010  ...           0.0   \n",
       "4278 -317.29916 -316.92715 -320.76240 -322.99478  ...           0.0   \n",
       "4279 -321.89062 -323.60220 -324.45087 -324.01114  ...           0.0   \n",
       "4280 -317.15750 -310.82544 -315.87380 -322.21048  ...           0.0   \n",
       "4281 -321.32846 -322.47766 -322.60980 -321.89868  ...           0.0   \n",
       "\n",
       "      feature_9993  feature_9994  feature_9995  feature_9996  feature_9997  \\\n",
       "0              0.0           0.0           0.0           0.0           0.0   \n",
       "1              0.0           0.0           0.0           0.0           0.0   \n",
       "2              0.0           0.0           0.0           0.0           0.0   \n",
       "3              0.0           0.0           0.0           0.0           0.0   \n",
       "4              0.0           0.0           0.0           0.0           0.0   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "4277           0.0           0.0           0.0           0.0           0.0   \n",
       "4278           0.0           0.0           0.0           0.0           0.0   \n",
       "4279           0.0           0.0           0.0           0.0           0.0   \n",
       "4280           0.0           0.0           0.0           0.0           0.0   \n",
       "4281           0.0           0.0           0.0           0.0           0.0   \n",
       "\n",
       "      feature_9998  feature_9999  label  gender  \n",
       "0              0.0           0.0      1  Female  \n",
       "1              0.0           0.0      1  Female  \n",
       "2              0.0           0.0      1  Female  \n",
       "3              0.0           0.0      1  Female  \n",
       "4              0.0           0.0      1  Female  \n",
       "...            ...           ...    ...     ...  \n",
       "4277           0.0           0.0      0    Male  \n",
       "4278           0.0           0.0      0    Male  \n",
       "4279           0.0           0.0      0    Male  \n",
       "4280           0.0           0.0      0    Male  \n",
       "4281           0.0           0.0      0    Male  \n",
       "\n",
       "[4282 rows x 10002 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03736499",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['gender','label'], axis=1)\n",
    "y = data['label']\n",
    "\n",
    "X_str = X.apply(lambda row:' '.join(row.astype(str)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35d0a670",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = X_str.astype('str').to_list()\n",
    "labels = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a471d378",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "all_embeddings = []\n",
    "all_labels = []\n",
    "\n",
    "for i in range(0, len(texts), batch_size):\n",
    "    batch_texts = texts[i:i+batch_size]\n",
    "    batch_labels = labels[i:i+batch_size]\n",
    "    inputs = tokenizer(batch_texts, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = lora_model(**inputs)\n",
    "        batch_embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "\n",
    "    all_embeddings.append(batch_embeddings)\n",
    "    all_labels.extend(batch_labels)\n",
    "\n",
    "all_embeddings = np.vstack(all_embeddings)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_embeddings, all_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41d5057f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.9171528588098017\n",
      "Random Forest Precision: 0.9565217391304348\n",
      "Random Forest Recall: 0.7829181494661922\n",
      "Random Forest F1-Score: 0.8610567514677103\n",
      "CPU times: total: 18.9 s\n",
      "Wall time: 20.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf_classifier = RandomForestClassifier(max_depth=20, min_samples_leaf=4, n_estimators=400)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "rf_predictions = rf_classifier.predict(X_test)\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, rf_predictions))\n",
    "print(\"Random Forest Precision:\", precision_score(y_test, rf_predictions))\n",
    "print(\"Random Forest Recall:\", recall_score(y_test, rf_predictions))\n",
    "print(\"Random Forest F1-Score:\", f1_score(y_test, rf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "049612f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.9148191365227538\n",
      "SVM Precision: 0.940677966101695\n",
      "SVM Recall: 0.7900355871886121\n",
      "SVM F1-Score: 0.8588007736943907\n"
     ]
    }
   ],
   "source": [
    "svm_classifier = SVC(C=1, kernel='linear', gamma=0.001, random_state=42)\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "svm_predictions = svm_classifier.predict(X_test)\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, svm_predictions))\n",
    "print(\"SVM Precision:\", precision_score(y_test, svm_predictions))\n",
    "print(\"SVM Recall:\", recall_score(y_test, svm_predictions))\n",
    "print(\"SVM F1-Score:\", f1_score(y_test, svm_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56f13044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.7712952158693116\n",
      "Naive Bayes Precision: 0.6307692307692307\n",
      "Naive Bayes Recall: 0.7295373665480427\n",
      "Naive Bayes F1-Score: 0.6765676567656765\n"
     ]
    }
   ],
   "source": [
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "nb_predictions = nb_classifier.predict(X_test)\n",
    "print(\"Naive Bayes Accuracy:\", accuracy_score(y_test, nb_predictions))\n",
    "print(\"Naive Bayes Precision:\", precision_score(y_test, nb_predictions))\n",
    "print(\"Naive Bayes Recall:\", recall_score(y_test, nb_predictions))\n",
    "print(\"Naive Bayes F1-Score:\", f1_score(y_test, nb_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9663b0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.9358226371061844\n",
      "XGBoost Precision: 0.94140625\n",
      "XGBoost Recall: 0.8576512455516014\n",
      "XGBoost F1-Score: 0.8975791433891993\n"
     ]
    }
   ],
   "source": [
    "xgb_classifier = XGBClassifier()\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "xgb_predictions = xgb_classifier.predict(X_test)\n",
    "print(\"XGBoost Accuracy:\", accuracy_score(y_test, xgb_predictions))\n",
    "print(\"XGBoost Precision:\", precision_score(y_test, xgb_predictions))\n",
    "print(\"XGBoost Recall:\", recall_score(y_test, xgb_predictions))\n",
    "print(\"XGBoost F1-Score:\", f1_score(y_test, xgb_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618eba00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
